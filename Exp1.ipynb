{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:63: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lab106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix as con\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "10 5\n",
      "[[ 635    0   40]\n",
      " [   3 1241  308]\n",
      " [  42  291 3375]]\n",
      "0.884767290669483\n",
      "\n",
      "\n",
      "10 10\n",
      "[[ 643    1   31]\n",
      " [   7 1270  275]\n",
      " [  19  167 3522]]\n",
      "0.9157593359111067\n",
      "\n",
      "\n",
      "10 15\n",
      "[[ 653    0   22]\n",
      " [   2 1289  261]\n",
      " [  23  116 3569]]\n",
      "0.9285667240136043\n",
      "\n",
      "\n",
      "10 20\n",
      "[[ 649    2   24]\n",
      " [   2 1380  170]\n",
      " [  12  132 3564]]\n",
      "0.9423802385859721\n",
      "\n",
      "\n",
      "10 25\n",
      "[[ 649    2   24]\n",
      " [   4 1392  156]\n",
      " [  20  143 3545]]\n",
      "0.9411946900142516\n",
      "\n",
      "\n",
      "10 30\n",
      "[[ 655    4   16]\n",
      " [   2 1401  149]\n",
      " [  12  129 3567]]\n",
      "0.9474335825937852\n",
      "\n",
      "\n",
      "10 35\n",
      "[[ 659    3   13]\n",
      " [   4 1395  153]\n",
      " [  13  110 3585]]\n",
      "0.9501274691831185\n",
      "\n",
      "\n",
      "10 40\n",
      "[[ 653    2   20]\n",
      " [   1 1430  121]\n",
      " [  15  117 3576]]\n",
      "0.9534956081330449\n",
      "\n",
      "\n",
      "10 45\n",
      "[[ 653    0   22]\n",
      " [   3 1426  123]\n",
      " [   7  113 3588]]\n",
      "0.9548480873944618\n",
      "\n",
      "\n",
      "10 50\n",
      "[[ 660    0   15]\n",
      " [   2 1458   92]\n",
      " [  13  103 3592]]\n",
      "0.9620911191737498\n",
      "\n",
      "\n",
      "15 5\n",
      "[[ 655    2   18]\n",
      " [   2 1449  101]\n",
      " [   9   99 3600]]\n",
      "0.9610790308935332\n",
      "\n",
      "\n",
      "15 10\n",
      "[[ 656    2   17]\n",
      " [   3 1429  120]\n",
      " [   7   98 3603]]\n",
      "0.9583842926170076\n",
      "\n",
      "\n",
      "15 15\n",
      "[[ 656    3   16]\n",
      " [   2 1433  117]\n",
      " [  11   74 3623]]\n",
      "0.9624232771787578\n",
      "\n",
      "\n",
      "15 20\n",
      "[[ 660    1   14]\n",
      " [   5 1442  105]\n",
      " [  19   82 3607]]\n",
      "0.9619233367968614\n",
      "\n",
      "\n",
      "15 25\n",
      "[[ 661    1   13]\n",
      " [   3 1455   94]\n",
      " [   7  116 3585]]\n",
      "0.9605717092226367\n",
      "\n",
      "\n",
      "15 30\n",
      "[[ 656    5   14]\n",
      " [   4 1456   92]\n",
      " [  13   98 3597]]\n",
      "0.9619210656310152\n",
      "\n",
      "\n",
      "15 35\n",
      "[[ 663    0   12]\n",
      " [   2 1465   85]\n",
      " [  12   75 3621]]\n",
      "0.9686567757394065\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bd44a14dbae8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                     batch_size=batch_size)\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3095\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3096\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3097\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3098\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1438\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1439\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1440\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1441\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1442\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# network parameters\n",
    "batch_size = 50  # 分批，每一批大小为100\n",
    "epochs = 100\n",
    "original_dim = 94  # 输入94维\n",
    "intermediate_dim1 = 74  # 隐藏层1\n",
    "intermediate_dim2 = 32  # 隐藏层2\n",
    "latent_dim = 2 # 隐变量2维\n",
    "out1_dim = 94  # 重构x\n",
    "out2_dim = 3   # 分类y\n",
    "\n",
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
    "# z = z_mean + sqrt(var)*eps\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling\n",
    "        fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    # K is the keras backend\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# VAE model = encoder + decoder\n",
    "# build encoder model\n",
    "\n",
    "x = Input(shape=(original_dim,), name='input') # 维数为original_dim（94），数量不确定\n",
    "h1 = Dense(intermediate_dim1, activation='relu')(x)\n",
    "h2 = Dense(intermediate_dim2, activation='relu')(h1)\n",
    "\n",
    "# 算p(Z|X)的均值和方差\n",
    "z_mean = Dense(latent_dim, name='z_mean')(h2)  # 隐层均值，输入为h，输出维数为2\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(h2)  # 隐层方差，输入为h，输出维数为2\n",
    "\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary\n",
    "# with the TensorFlow backend\n",
    "z = Lambda(sampling,\n",
    "           output_shape=(latent_dim,),\n",
    "           name='z')([z_mean, z_log_var])\n",
    "\n",
    "decoder_h1 = Dense(intermediate_dim2, activation='relu')  # 32个神经元\n",
    "decoder_h2 = Dense(intermediate_dim1, activation='relu')  # 74个神经元\n",
    "decoder_mean = Dense(out1_dim, activation='sigmoid', name='output1')  # 94个神经元\n",
    "decoder_y = Dense(out2_dim, activation='softmax', name='output2')\n",
    "\n",
    "# h1_decoded = decoder_h1(z)\n",
    "h1_decoded = decoder_h1(z)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    "h2_decoded = decoder_h2(h1_decoded)\n",
    "x_decoded = decoder_mean(h2_decoded)\n",
    "y_clf = decoder_y(x_decoded)\n",
    "\n",
    "for L in range(5, 55, 5):\n",
    "    for a in range(5, 55, 5):\n",
    "#       print(L, a)\n",
    "        M=a*L\n",
    "        H=a*a*L\n",
    "        cost=[[1,H,H],\n",
    "              [M,1,M],\n",
    "              [L,L,1]]\n",
    "\n",
    "        def loss1(x, x_decoded):    \n",
    "            xent_loss = K.sum(K.binary_crossentropy(tf.convert_to_tensor(x), tf.convert_to_tensor(x_decoded)), axis=-1) # 重构误差\n",
    "            kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1) # KL散度\n",
    "            vae_loss = xent_loss + kl_loss \n",
    "            return vae_loss\n",
    "\n",
    "        def loss2(y_true, y_pred):\n",
    "#           clf_loss = -tf.reduce_mean(tf.convert_to_tensor(y_true) * tf.log(tf.convert_to_tensor(y_pred))) * cost[np.argmax(y_true)][np.argmax(y_pred)]\n",
    "            clf_loss = -tf.reduce_mean(tf.convert_to_tensor(y_true) * tf.log(tf.convert_to_tensor(y_pred))) \n",
    "#           clf_loss = -tf.reduce_mean(np.argmax(y_true) * tf.log(np.argmax(y_pred)) * cost[np.argmax(y_true)][np.argmax(y_pred)]\n",
    "            return clf_loss\n",
    "\n",
    "\n",
    "        vae=Model(inputs = x, outputs = [x_decoded, y_clf])\n",
    "        vae.compile(optimizer='adam',\n",
    "                    loss = {'output1':loss1,'output2':loss2},\n",
    "                    loss_weights = {'output1':1.0,'output2':100})\n",
    "\n",
    "\n",
    "        data = pd.read_csv(\"Full_Dataset-Dmax-TTT.csv\")\n",
    "        # 打乱数据顺序\n",
    "        data = shuffle(data)\n",
    "        # shuffle(data)\n",
    "        # print(data.iloc[0:1,0:95])\n",
    "        X = data.iloc[0:5935,0:94]\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        X = min_max_scaler.fit_transform(X)\n",
    "        Y = pd.get_dummies(data['Phase Formation'])\n",
    "        Y = Y.values\n",
    "\n",
    "        KF = KFold(n_splits = 10,shuffle=True,random_state=100)\n",
    "\n",
    "        sumCon = [[0, 0, 0],\n",
    "                  [0, 0, 0],\n",
    "                  [0, 0, 0]]\n",
    "\n",
    "        sumAccuracy = 0\n",
    "\n",
    "        for train_index, test_index in KF.split(X):\n",
    "#     print('\\n',i)\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            x_train, x_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = Y[train_index], Y[test_index]\n",
    "#     print('训练集数量:',x_train.shape,'测试集数量:',x_test.shape) #结果表明每次划分的数量\n",
    "#     print(y_train)\n",
    "            vae.fit({'input':x_train}, \n",
    "                    {'output1':x_train,'output2':y_train}, \n",
    "                    shuffle=True,\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    batch_size=batch_size)\n",
    "    \n",
    "            y1, y2 = vae.predict(x_test)\n",
    "    \n",
    "            y_predict=[]\n",
    "            for i in y2:\n",
    "                y_predict.append(np.argmax(i))\n",
    "#               print(y_predict)\n",
    "\n",
    "            y_true =[]\n",
    "            for j in y_test:\n",
    "                y_true.append(np.argmax(j))\n",
    "#               print(y_true)\n",
    "\n",
    "            print('混淆矩阵：')\n",
    "            print(con(y_true,y_predict))\n",
    "            sumCon += con(y_true,y_predict)\n",
    "    \n",
    "            print('Accuracy:')\n",
    "            print(accuracy_score(y_true, y_predict))\n",
    "            sumAccuracy += accuracy_score(y_true, y_predict)\n",
    "#             i += 1\n",
    "\n",
    "        print('\\n')\n",
    "        print(L, a)\n",
    "        print(sumCon)\n",
    "        print(sumAccuracy / 10.0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
